{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171820b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a215b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0de36f",
   "metadata": {},
   "source": [
    "# Autogluon 기본 사용법\n",
    "* 1. 데이터 로딩\n",
    "* 2. 타겟변수 지정\n",
    "* 3. TabularPredictor 설정, (타겟변수, 모델 성능 지표) - 모델설정\n",
    "* 4. 훈련(데이터, 제한시간설정, 분석사전설정 지정) - .fit()\n",
    "* 5. 데이터에서 일부 데이터를 테스트 데이터로 추출 = .sample()\n",
    "* 6. 분석이 끝난 모델로 테스트 데이터에서 추론 .predict()\n",
    "* 7. 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a8530",
   "metadata": {},
   "source": [
    "# 1. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f74d4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass      education  ...  hours-per-week  native-country   class\n",
       "0   25     Private           11th  ...              40   United-States   <=50K\n",
       "1   38     Private        HS-grad  ...              50   United-States   <=50K\n",
       "2   28   Local-gov     Assoc-acdm  ...              40   United-States    >50K\n",
       "3   44     Private   Some-college  ...              40   United-States    >50K\n",
       "4   18         NaN   Some-college  ...              30   United-States   <=50K\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/salary2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f584293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       46043 non-null  object\n",
      " 2   education       48842 non-null  object\n",
      " 3   education-num   48842 non-null  int64 \n",
      " 4   marital-status  48842 non-null  object\n",
      " 5   occupation      46033 non-null  object\n",
      " 6   relationship    48842 non-null  object\n",
      " 7   race            48842 non-null  object\n",
      " 8   sex             48842 non-null  object\n",
      " 9   capital-gain    48842 non-null  int64 \n",
      " 10  capital-loss    48842 non-null  int64 \n",
      " 11  hours-per-week  48842 non-null  int64 \n",
      " 12  native-country  47985 non-null  object\n",
      " 13  class           48842 non-null  object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dece830",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63d5c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, stratify=data['class'], test_size=0.4, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e71aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12689</th>\n",
       "      <td>49</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30011</th>\n",
       "      <td>45</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28454</th>\n",
       "      <td>55</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>2246</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17394</th>\n",
       "      <td>69</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31597</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20424</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28686</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30381</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48693</th>\n",
       "      <td>61</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44534</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29305 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  ...  native-country   class\n",
       "12689   49   Self-emp-not-inc  ...   United-States   <=50K\n",
       "30011   45            Private  ...   United-States    >50K\n",
       "28454   55          Local-gov  ...   United-States    >50K\n",
       "17394   69            Private  ...   United-States   <=50K\n",
       "31597   21            Private  ...   United-States   <=50K\n",
       "...    ...                ...  ...             ...     ...\n",
       "20424   31            Private  ...   United-States    >50K\n",
       "28686   18                NaN  ...   United-States   <=50K\n",
       "30381   28            Private  ...   United-States   <=50K\n",
       "48693   61            Private  ...   United-States   <=50K\n",
       "44534   31            Private  ...   United-States   <=50K\n",
       "\n",
       "[29305 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945ddac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22332</th>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33515</th>\n",
       "      <td>57</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39475</th>\n",
       "      <td>37</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11140</th>\n",
       "      <td>19</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>41</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43439</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>28</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46661</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28427</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29562</th>\n",
       "      <td>26</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19537 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  ...  native-country   class\n",
       "22332   56            NaN  ...   United-States   <=50K\n",
       "33515   57        Private  ...   United-States   <=50K\n",
       "39475   37      State-gov  ...   United-States   <=50K\n",
       "11140   19        Private  ...   United-States   <=50K\n",
       "39998   41      State-gov  ...   United-States   <=50K\n",
       "...    ...            ...  ...             ...     ...\n",
       "43439   21        Private  ...   United-States   <=50K\n",
       "3527    28   Self-emp-inc  ...   United-States   <=50K\n",
       "46661   27        Private  ...   United-States   <=50K\n",
       "28427   38        Private  ...   United-States   <=50K\n",
       "29562   26        Private  ...             NaN   <=50K\n",
       "\n",
       "[19537 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a6ece",
   "metadata": {},
   "source": [
    "# 2. 타겟변수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74cc0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"class\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043c26a",
   "metadata": {},
   "source": [
    "# 3. 제한시간, 검정지표(평가지표, accuracy, rmse, roc_auc) 지정  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c66456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초 단위로 제한시간 지정  300초는 5분, \n",
    "time_limit = 300\n",
    "# 성능지표(accuracy, roc_auc, root_mean_squared_error, r2, f1, recall, precision, roc_auc, mean_squared_error) \n",
    "metric = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09dc3ff",
   "metadata": {},
   "source": [
    "# 4. 모델정의 TablularPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5506e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_024644\"\n"
     ]
    }
   ],
   "source": [
    "model = TabularPredictor(label=target_column, eval_metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d38d125",
   "metadata": {},
   "source": [
    "# 5. 모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d798c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       13.33 GB / 14.61 GB (91.2%)\n",
      "Disk Space Avail:   22.89 GB / 223.03 GB (10.3%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_024644\"\n",
      "Train Data Rows:    29305\n",
      "Train Data Columns: 13\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13670.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 16.07 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 5 | ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.3s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.35 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.08530967411704488, Train Rows: 26805, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.63s of the 299.63s of remaining time.\n",
      "\t0.8284\t = Validation score   (accuracy)\n",
      "\t2.69s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 296.82s of the 296.82s of remaining time.\n",
      "\t0.8256\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 296.66s of the 296.66s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 294.68s of the 294.68s of remaining time.\n",
      "\t0.8764\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 294.07s of the 294.06s of remaining time.\n",
      "\t0.8504\t = Validation score   (accuracy)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 289.82s of the 289.82s of remaining time.\n",
      "\t0.8512\t = Validation score   (accuracy)\n",
      "\t2.2s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 285.79s of the 285.79s of remaining time.\n",
      "<frozen importlib._bootstrap>:241: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n",
      "\t0.8784\t = Validation score   (accuracy)\n",
      "\t12.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 273.7s of the 273.7s of remaining time.\n",
      "\t0.8428\t = Validation score   (accuracy)\n",
      "\t1.89s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 269.78s of the 269.78s of remaining time.\n",
      "\t0.8432\t = Validation score   (accuracy)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 265.86s of the 265.86s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t0.8628\t = Validation score   (accuracy)\n",
      "\t212.98s\t = Training   runtime\n",
      "\t1.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 51.77s of the 51.77s of remaining time.\n",
      "\t0.8772\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 50.44s of the 50.43s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t0.8396\t = Validation score   (accuracy)\n",
      "\t50.51s\t = Training   runtime\n",
      "\t1.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.63s of the -1.33s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 1.0}\n",
      "\t0.8784\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 301.73s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 275701.6 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_024644\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x7f28183ef1f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, time_limit=time_limit, presets='medium_quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1609b7a2",
   "metadata": {},
   "source": [
    "# 6. 생성된 모델에 테스트 데이터 넣어 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a87a22ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4275e261",
   "metadata": {},
   "source": [
    "# 7. 모델 성능 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81664cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 13 features using 5000 rows with 5 shuffle sets...\n",
      "\t2.7s\t= Expected runtime (0.54s per shuffle set)\n",
      "\t0.93s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_data)\n",
    "result_df = pd.DataFrame([result], index=[0])\n",
    "# 여러 모델 성능 비교\n",
    "leader_board = model.leaderboard(test_data)\n",
    "# 중요 변수 출력\n",
    "feature_importance = model.feature_importance(test_data)\n",
    "best_model_name = model.model_best\n",
    "# best모델 로딩\n",
    "best_model = model._trainer.load_model(best_model_name)\n",
    "best_model_params = best_model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e6eac",
   "metadata": {},
   "source": [
    "# 8 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8beffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result_df ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.640071</td>\n",
       "      <td>0.928474</td>\n",
       "      <td>0.712988</td>\n",
       "      <td>0.794845</td>\n",
       "      <td>0.646417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy       mcc  ...        f1  precision    recall\n",
       "0  0.875467           0.796967  0.640071  ...  0.712988   0.794845  0.646417\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== leader_board ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>12.016510</td>\n",
       "      <td>0.055694</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>12.016510</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.875467</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.064360</td>\n",
       "      <td>0.009068</td>\n",
       "      <td>12.171801</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.155292</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.875416</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.099724</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>1.275517</td>\n",
       "      <td>0.099724</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>1.275517</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.872601</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.031327</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.571997</td>\n",
       "      <td>0.031327</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.571997</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.867226</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.058394</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>1.902644</td>\n",
       "      <td>0.058394</td>\n",
       "      <td>0.012007</td>\n",
       "      <td>1.902644</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.856375</td>\n",
       "      <td>0.8628</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>7.895960</td>\n",
       "      <td>1.053628</td>\n",
       "      <td>212.976156</td>\n",
       "      <td>7.895960</td>\n",
       "      <td>1.053628</td>\n",
       "      <td>212.976156</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.855044</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.518059</td>\n",
       "      <td>0.154923</td>\n",
       "      <td>2.766668</td>\n",
       "      <td>1.518059</td>\n",
       "      <td>0.154923</td>\n",
       "      <td>2.766668</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.854891</td>\n",
       "      <td>0.8512</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.588107</td>\n",
       "      <td>0.144864</td>\n",
       "      <td>2.201828</td>\n",
       "      <td>1.588107</td>\n",
       "      <td>0.144864</td>\n",
       "      <td>2.201828</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.849670</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.805903</td>\n",
       "      <td>0.166710</td>\n",
       "      <td>1.909244</td>\n",
       "      <td>1.805903</td>\n",
       "      <td>0.166710</td>\n",
       "      <td>1.909244</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.849209</td>\n",
       "      <td>0.8428</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.967846</td>\n",
       "      <td>0.155506</td>\n",
       "      <td>1.889012</td>\n",
       "      <td>1.967846</td>\n",
       "      <td>0.155506</td>\n",
       "      <td>1.889012</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.839638</td>\n",
       "      <td>0.8396</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>10.061408</td>\n",
       "      <td>1.148505</td>\n",
       "      <td>50.506840</td>\n",
       "      <td>10.061408</td>\n",
       "      <td>1.148505</td>\n",
       "      <td>50.506840</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.829708</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.370809</td>\n",
       "      <td>0.064561</td>\n",
       "      <td>2.694464</td>\n",
       "      <td>0.370809</td>\n",
       "      <td>0.064561</td>\n",
       "      <td>2.694464</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.827251</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.419417</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.031494</td>\n",
       "      <td>0.419417</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.031494</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  ...  can_infer fit_order\n",
       "0              CatBoost    0.875467  ...       True         7\n",
       "1   WeightedEnsemble_L2    0.875467  ...       True        13\n",
       "2               XGBoost    0.875416  ...       True        11\n",
       "3              LightGBM    0.872601  ...       True         4\n",
       "4            LightGBMXT    0.867226  ...       True         3\n",
       "5       NeuralNetFastAI    0.856375  ...       True        10\n",
       "6      RandomForestGini    0.855044  ...       True         5\n",
       "7      RandomForestEntr    0.854891  ...       True         6\n",
       "8        ExtraTreesEntr    0.849670  ...       True         9\n",
       "9        ExtraTreesGini    0.849209  ...       True         8\n",
       "10       NeuralNetTorch    0.839638  ...       True        12\n",
       "11       KNeighborsUnif    0.829708  ...       True         1\n",
       "12       KNeighborsDist    0.827251  ...       True         2\n",
       "\n",
       "[13 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== feature_importance ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.04364</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>7.813844e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.048183</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0.01928</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>1.993044e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>0.014754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.01776</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>4.454331e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026975</td>\n",
       "      <td>0.008545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.01772</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>5.629572e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>0.007946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.01580</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>2.696615e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019803</td>\n",
       "      <td>0.011797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.01464</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>2.603090e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.010964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>8.642234e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.002418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0.00616</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>4.075653e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.004427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.00608</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>6.665418e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>-0.000532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.00428</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>6.017823e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>1.417555e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.000653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>-0.00004</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>5.510703e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>-0.001387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.00056</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>9.110961e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>-0.002139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev       p_value  n  p99_high   p99_low\n",
       "capital-gain       0.04364  0.002206  7.813844e-07  5  0.048183  0.039097\n",
       "occupation         0.01928  0.002198  1.993044e-05  5  0.023806  0.014754\n",
       "relationship       0.01776  0.004475  4.454331e-04  5  0.026975  0.008545\n",
       "marital-status     0.01772  0.004747  5.629572e-04  5  0.027494  0.007946\n",
       "age                0.01580  0.001944  2.696615e-05  5  0.019803  0.011797\n",
       "capital-loss       0.01464  0.001785  2.603090e-05  5  0.018316  0.010964\n",
       "education-num      0.00632  0.001895  8.642234e-04  5  0.010222  0.002418\n",
       "workclass          0.00616  0.000841  4.075653e-05  5  0.007893  0.004427\n",
       "hours-per-week     0.00608  0.003211  6.665418e-03  5  0.012692 -0.000532\n",
       "education          0.00428  0.002194  6.017823e-03  5  0.008797 -0.000237\n",
       "native-country     0.00024  0.000434  1.417555e-01  5  0.001133 -0.000653\n",
       "race              -0.00004  0.000654  5.510703e-01  5  0.001307 -0.001387\n",
       "sex               -0.00056  0.000767  9.110961e-01  5  0.001019 -0.002139"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model_name, params ====================\n",
      "best_model_name:  WeightedEnsemble_L2 \n",
      "params:  {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*20, \"result_df\", \"=\"*20)\n",
    "display(result_df)\n",
    "print()\n",
    "print(\"=\"*20, \"leader_board\", \"=\"*20)\n",
    "display(leader_board)\n",
    "print()\n",
    "print(\"=\"*20, \"feature_importance\", \"=\"*20)\n",
    "display(feature_importance)\n",
    "print()\n",
    "print(\"=\"*20, \"best_model_name, params\", \"=\"*20)\n",
    "print(\"best_model_name: \", best_model_name, \"\\nparams: \", best_model_params)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50356e6",
   "metadata": {},
   "source": [
    "# 함수화하고 분석 간단히 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c051c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automl(data, target, time=300, metric=None):\n",
    "     \n",
    "    if metric in (\"accuracy\", \"roc_auc\", \"recall\", \"precision\", \"f1\"):\n",
    "        train_data, test_data = train_test_split(data, stratify=data[target], test_size=0.4, random_state=10)\n",
    "    else:\n",
    "        train_data, test_data = train_test_split(data, test_size=0.4, random_state=10)\n",
    "        \n",
    "    model = TabularPredictor(label=target, eval_metric=metric)\n",
    "    model.fit(train_data, time_limit=time, presets='medium_quality')\n",
    "    pred = model.predict(test_data)\n",
    "\n",
    "    result = model.evaluate(test_data)\n",
    "    result_df = pd.DataFrame([result], index=[0])\n",
    "    # 여러 모델 성능 비교\n",
    "    leader_board = model.leaderboard(test_data)\n",
    "    # 중요 변수 출력\n",
    "    feature_importance = model.feature_importance(test_data)\n",
    "    best_model_name = model.model_best\n",
    "    # best모델 로딩\n",
    "    best_model = model._trainer.load_model(best_model_name)\n",
    "    best_model_params = best_model.params\n",
    "\n",
    "    print(\"=\"*20, \"result_df\", \"=\"*20)\n",
    "    display(result_df)\n",
    "    print()\n",
    "    print(\"=\"*20, \"leader_board\", \"=\"*20)\n",
    "    display(leader_board)\n",
    "    print()\n",
    "    print(\"=\"*20, \"feature_importance\", \"=\"*20)\n",
    "    display(feature_importance)\n",
    "    print()\n",
    "    print(\"=\"*20, \"best_model_name, params\", \"=\"*20)\n",
    "    print(\"best_model_name: \", best_model_name, \"\\nparams: \", best_model_params)\n",
    "    print()\n",
    "    return best_model, result_df, leader_board, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26af3305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/Taitanic_train.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cfe255a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_033700\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       13.48 GB / 14.61 GB (92.2%)\n",
      "Disk Space Avail:   21.76 GB / 223.03 GB (9.8%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_033700\"\n",
      "Train Data Rows:    534\n",
      "Train Data Columns: 11\n",
      "Label Column:       Survived\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13800.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 4\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])          : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('object', [])       : 4 | ['Sex', 'Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('object', ['text']) : 1 | ['Name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    : 3 | ['Ticket', 'Cabin', 'Embarked']\n",
      "\t\t('float', [])                       : 2 | ['Age', 'Fare']\n",
      "\t\t('int', [])                         : 4 | ['PassengerId', 'Pclass', 'SibSp', 'Parch']\n",
      "\t\t('int', ['binned', 'text_special']) : 8 | ['Name.char_count', 'Name.word_count', 'Name.capital_ratio', 'Name.lower_ratio', 'Name.special_ratio', ...]\n",
      "\t\t('int', ['bool'])                   : 1 | ['Sex']\n",
      "\t\t('int', ['text_ngram'])             : 5 | ['__nlp__.miss', '__nlp__.mr', '__nlp__.mrs', '__nlp__.william', '__nlp__._total_']\n",
      "\t0.4s = Fit runtime\n",
      "\t11 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.44s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 427, Val Rows: 107\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.56s of the 299.56s of remaining time.\n",
      "\t0.5794\t = Validation score   (accuracy)\n",
      "\t2.4s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 297.05s of the 297.04s of remaining time.\n",
      "\t0.5514\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 296.98s of the 296.98s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "\t0.8224\t = Validation score   (accuracy)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 295.73s of the 295.73s of remaining time.\n",
      "\t0.8411\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 295.44s of the 295.44s of remaining time.\n",
      "\t0.8131\t = Validation score   (accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 294.25s of the 294.24s of remaining time.\n",
      "\t0.8224\t = Validation score   (accuracy)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 292.69s of the 292.69s of remaining time.\n",
      "\t0.8411\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 291.5s of the 291.5s of remaining time.\n",
      "\t0.785\t = Validation score   (accuracy)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 290.49s of the 290.49s of remaining time.\n",
      "\t0.8131\t = Validation score   (accuracy)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 289.43s of the 289.43s of remaining time.\n",
      "No improvement since epoch 6: early stopping\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t0.8131\t = Validation score   (accuracy)\n",
      "\t11.22s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 278.04s of the 278.04s of remaining time.\n",
      "\t0.8131\t = Validation score   (accuracy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.39s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 277.6s of the 277.59s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:1623: FutureWarning: \n",
      "The format of the columns of the 'remainder' transformer in ColumnTransformer.transformers_ will change in version 1.7 to match the format of the other transformers.\n",
      "At the moment the remainder columns are stored as indices (of type int). With the same ColumnTransformer configuration, in the future they will be stored as column names (of type str).\n",
      "To use the new behavior now and suppress this warning, use ColumnTransformer(force_int_remainder_cols=False).\n",
      "\n",
      "  warnings.warn(\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t0.8037\t = Validation score   (accuracy)\n",
      "\t8.06s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 269.44s of the 269.44s of remaining time.\n",
      "\t0.8131\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.56s of the 268.61s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 1.0}\n",
      "\t0.8411\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 31.73s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 25944.6 rows/s (107 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_033700\")\n",
      "Computing feature importance via permutation shuffling for 11 features using 357 rows with 5 shuffle sets...\n",
      "\t2.25s\t= Expected runtime (0.45s per shuffle set)\n",
      "\t0.6s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== result_df ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817927</td>\n",
       "      <td>0.778828</td>\n",
       "      <td>0.593756</td>\n",
       "      <td>0.856475</td>\n",
       "      <td>0.716157</td>\n",
       "      <td>0.811881</td>\n",
       "      <td>0.640625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy       mcc   roc_auc        f1  precision  \\\n",
       "0  0.817927           0.778828  0.593756  0.856475  0.716157   0.811881   \n",
       "\n",
       "     recall  \n",
       "0  0.640625  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== leader_board ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.817927</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.249972</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.249972</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.817927</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.410796</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.160825</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.155555</td>\n",
       "      <td>0.113408</td>\n",
       "      <td>11.220496</td>\n",
       "      <td>0.155555</td>\n",
       "      <td>0.113408</td>\n",
       "      <td>11.220496</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.812325</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.312703</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>8.061890</td>\n",
       "      <td>0.312703</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>8.061890</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.736879</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>0.736879</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.806723</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.055758</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.391832</td>\n",
       "      <td>0.055758</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.391832</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.806723</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.225424</td>\n",
       "      <td>0.076075</td>\n",
       "      <td>0.976612</td>\n",
       "      <td>0.225424</td>\n",
       "      <td>0.076075</td>\n",
       "      <td>0.976612</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.841121</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>1.137179</td>\n",
       "      <td>0.013096</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>1.137179</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.223681</td>\n",
       "      <td>0.072017</td>\n",
       "      <td>1.006399</td>\n",
       "      <td>0.223681</td>\n",
       "      <td>0.072017</td>\n",
       "      <td>1.006399</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.801120</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.229940</td>\n",
       "      <td>0.077816</td>\n",
       "      <td>0.860995</td>\n",
       "      <td>0.229940</td>\n",
       "      <td>0.077816</td>\n",
       "      <td>0.860995</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.789916</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>1.184455</td>\n",
       "      <td>0.009885</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>1.184455</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.177412</td>\n",
       "      <td>0.070021</td>\n",
       "      <td>0.854581</td>\n",
       "      <td>0.177412</td>\n",
       "      <td>0.070021</td>\n",
       "      <td>0.854581</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.669468</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.071184</td>\n",
       "      <td>2.398025</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.071184</td>\n",
       "      <td>2.398025</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0              LightGBM    0.817927   0.841121    accuracy        0.009537   \n",
       "1   WeightedEnsemble_L2    0.817927   0.841121    accuracy        0.015003   \n",
       "2       NeuralNetFastAI    0.815126   0.813084    accuracy        0.155555   \n",
       "3        NeuralNetTorch    0.812325   0.803738    accuracy        0.312703   \n",
       "4         LightGBMLarge    0.809524   0.813084    accuracy        0.017795   \n",
       "5               XGBoost    0.806723   0.813084    accuracy        0.055758   \n",
       "6      RandomForestEntr    0.806723   0.822430    accuracy        0.225424   \n",
       "7              CatBoost    0.803922   0.841121    accuracy        0.013096   \n",
       "8      RandomForestGini    0.803922   0.813084    accuracy        0.223681   \n",
       "9        ExtraTreesEntr    0.801120   0.813084    accuracy        0.229940   \n",
       "10           LightGBMXT    0.789916   0.822430    accuracy        0.009885   \n",
       "11       ExtraTreesGini    0.784314   0.785047    accuracy        0.177412   \n",
       "12       KNeighborsDist    0.669468   0.551402    accuracy        0.007651   \n",
       "13       KNeighborsUnif    0.666667   0.579439    accuracy        0.009359   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.003131   0.249972                 0.009537                0.003131   \n",
       "1        0.004124   0.410796                 0.005466                0.000993   \n",
       "2        0.113408  11.220496                 0.155555                0.113408   \n",
       "3        0.026331   8.061890                 0.312703                0.026331   \n",
       "4        0.003872   0.736879                 0.017795                0.003872   \n",
       "5        0.005378   0.391832                 0.055758                0.005378   \n",
       "6        0.076075   0.976612                 0.225424                0.076075   \n",
       "7        0.005139   1.137179                 0.013096                0.005139   \n",
       "8        0.072017   1.006399                 0.223681                0.072017   \n",
       "9        0.077816   0.860995                 0.229940                0.077816   \n",
       "10       0.006879   1.184455                 0.009885                0.006879   \n",
       "11       0.070021   0.854581                 0.177412                0.070021   \n",
       "12       0.005764   0.014848                 0.007651                0.005764   \n",
       "13       0.071184   2.398025                 0.009359                0.071184   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            0.249972            1       True          4  \n",
       "1            0.160825            2       True         14  \n",
       "2           11.220496            1       True         10  \n",
       "3            8.061890            1       True         12  \n",
       "4            0.736879            1       True         13  \n",
       "5            0.391832            1       True         11  \n",
       "6            0.976612            1       True          6  \n",
       "7            1.137179            1       True          7  \n",
       "8            1.006399            1       True          5  \n",
       "9            0.860995            1       True          9  \n",
       "10           1.184455            1       True          3  \n",
       "11           0.854581            1       True          8  \n",
       "12           0.014848            1       True          2  \n",
       "13           2.398025            1       True          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== feature_importance ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.012274</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5</td>\n",
       "      <td>0.174292</td>\n",
       "      <td>0.123747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>0.053782</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>5</td>\n",
       "      <td>0.068710</td>\n",
       "      <td>0.038853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>0.024090</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032837</td>\n",
       "      <td>0.015343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.022409</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>5</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.012419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.018095</td>\n",
       "      <td>5</td>\n",
       "      <td>0.034801</td>\n",
       "      <td>-0.006790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>5</td>\n",
       "      <td>0.021072</td>\n",
       "      <td>0.003578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.008964</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.010238</td>\n",
       "      <td>5</td>\n",
       "      <td>0.020058</td>\n",
       "      <td>-0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>5</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>-0.009842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>-0.000560</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.576678</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011944</td>\n",
       "      <td>-0.013064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             importance    stddev   p_value  n  p99_high   p99_low\n",
       "Sex            0.149020  0.012274  0.000005  5  0.174292  0.123747\n",
       "Pclass         0.053782  0.007251  0.000039  5  0.068710  0.038853\n",
       "Name           0.024090  0.004248  0.000111  5  0.032837  0.015343\n",
       "Fare           0.022409  0.004852  0.000248  5  0.032399  0.012419\n",
       "Embarked       0.014006  0.010100  0.018095  5  0.034801 -0.006790\n",
       "Cabin          0.012325  0.004248  0.001455  5  0.021072  0.003578\n",
       "Age            0.008964  0.005388  0.010238  5  0.020058 -0.002131\n",
       "PassengerId    0.006162  0.007773  0.075472  5  0.022167 -0.009842\n",
       "Parch          0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
       "Ticket         0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
       "SibSp         -0.000560  0.006073  0.576678  5  0.011944 -0.013064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== best_model_name, params ====================\n",
      "best_model_name:  WeightedEnsemble_L2 \n",
      "params:  {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<autogluon.core.models.ensemble.weighted_ensemble_model.WeightedEnsembleModel at 0x7fd0ffe076d0>,\n",
       "    accuracy  balanced_accuracy       mcc   roc_auc        f1  precision  \\\n",
       " 0  0.817927           0.778828  0.593756  0.856475  0.716157   0.811881   \n",
       " \n",
       "      recall  \n",
       " 0  0.640625  ,\n",
       "                   model  score_test  score_val eval_metric  pred_time_test  \\\n",
       " 0              LightGBM    0.817927   0.841121    accuracy        0.009537   \n",
       " 1   WeightedEnsemble_L2    0.817927   0.841121    accuracy        0.015003   \n",
       " 2       NeuralNetFastAI    0.815126   0.813084    accuracy        0.155555   \n",
       " 3        NeuralNetTorch    0.812325   0.803738    accuracy        0.312703   \n",
       " 4         LightGBMLarge    0.809524   0.813084    accuracy        0.017795   \n",
       " 5               XGBoost    0.806723   0.813084    accuracy        0.055758   \n",
       " 6      RandomForestEntr    0.806723   0.822430    accuracy        0.225424   \n",
       " 7              CatBoost    0.803922   0.841121    accuracy        0.013096   \n",
       " 8      RandomForestGini    0.803922   0.813084    accuracy        0.223681   \n",
       " 9        ExtraTreesEntr    0.801120   0.813084    accuracy        0.229940   \n",
       " 10           LightGBMXT    0.789916   0.822430    accuracy        0.009885   \n",
       " 11       ExtraTreesGini    0.784314   0.785047    accuracy        0.177412   \n",
       " 12       KNeighborsDist    0.669468   0.551402    accuracy        0.007651   \n",
       " 13       KNeighborsUnif    0.666667   0.579439    accuracy        0.009359   \n",
       " \n",
       "     pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       " 0        0.003131   0.249972                 0.009537                0.003131   \n",
       " 1        0.004124   0.410796                 0.005466                0.000993   \n",
       " 2        0.113408  11.220496                 0.155555                0.113408   \n",
       " 3        0.026331   8.061890                 0.312703                0.026331   \n",
       " 4        0.003872   0.736879                 0.017795                0.003872   \n",
       " 5        0.005378   0.391832                 0.055758                0.005378   \n",
       " 6        0.076075   0.976612                 0.225424                0.076075   \n",
       " 7        0.005139   1.137179                 0.013096                0.005139   \n",
       " 8        0.072017   1.006399                 0.223681                0.072017   \n",
       " 9        0.077816   0.860995                 0.229940                0.077816   \n",
       " 10       0.006879   1.184455                 0.009885                0.006879   \n",
       " 11       0.070021   0.854581                 0.177412                0.070021   \n",
       " 12       0.005764   0.014848                 0.007651                0.005764   \n",
       " 13       0.071184   2.398025                 0.009359                0.071184   \n",
       " \n",
       "     fit_time_marginal  stack_level  can_infer  fit_order  \n",
       " 0            0.249972            1       True          4  \n",
       " 1            0.160825            2       True         14  \n",
       " 2           11.220496            1       True         10  \n",
       " 3            8.061890            1       True         12  \n",
       " 4            0.736879            1       True         13  \n",
       " 5            0.391832            1       True         11  \n",
       " 6            0.976612            1       True          6  \n",
       " 7            1.137179            1       True          7  \n",
       " 8            1.006399            1       True          5  \n",
       " 9            0.860995            1       True          9  \n",
       " 10           1.184455            1       True          3  \n",
       " 11           0.854581            1       True          8  \n",
       " 12           0.014848            1       True          2  \n",
       " 13           2.398025            1       True          1  ,\n",
       "              importance    stddev   p_value  n  p99_high   p99_low\n",
       " Sex            0.149020  0.012274  0.000005  5  0.174292  0.123747\n",
       " Pclass         0.053782  0.007251  0.000039  5  0.068710  0.038853\n",
       " Name           0.024090  0.004248  0.000111  5  0.032837  0.015343\n",
       " Fare           0.022409  0.004852  0.000248  5  0.032399  0.012419\n",
       " Embarked       0.014006  0.010100  0.018095  5  0.034801 -0.006790\n",
       " Cabin          0.012325  0.004248  0.001455  5  0.021072  0.003578\n",
       " Age            0.008964  0.005388  0.010238  5  0.020058 -0.002131\n",
       " PassengerId    0.006162  0.007773  0.075472  5  0.022167 -0.009842\n",
       " Parch          0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
       " Ticket         0.000000  0.000000  0.500000  5  0.000000  0.000000\n",
       " SibSp         -0.000560  0.006073  0.576678  5  0.011944 -0.013064)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl(data, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dfadc11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (4.6.2.post1)\n",
      "Collecting fastapi<1.0 (from gradio)\n",
      "  Downloading fastapi-0.115.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.4.0 (from gradio)\n",
      "  Downloading gradio_client-1.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (0.25.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (3.10.7)\n",
      "Requirement already satisfied: packaging in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (10.4.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from gradio-client==1.4.0->gradio) (2024.9.0)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.0->gradio)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Collecting starlette<0.41.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
      "  Downloading starlette-0.40.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: requests in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.9.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/user/miniforge3/envs/automl/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.1.0-py3-none-any.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.4.0-py3-none-any.whl (319 kB)\n",
      "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.2-py3-none-any.whl (94 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Using cached ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading starlette-0.40.0-py3-none-any.whl (73 kB)\n",
      "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Installing collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, pydantic-core, markupsafe, h11, ffmpy, annotated-types, aiofiles, uvicorn, starlette, pydantic, httpcore, httpx, fastapi, gradio-client, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.1\n",
      "    Uninstalling MarkupSafe-3.0.1:\n",
      "      Successfully uninstalled MarkupSafe-3.0.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.17\n",
      "    Uninstalling pydantic-1.10.17:\n",
      "      Successfully uninstalled pydantic-1.10.17\n",
      "Successfully installed aiofiles-23.2.1 annotated-types-0.7.0 fastapi-0.115.2 ffmpy-0.4.0 gradio-5.1.0 gradio-client-1.4.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 markupsafe-2.1.5 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.9 semantic-version-2.10.0 starlette-0.40.0 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "116c2518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://2be9631a94060bb066.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2be9631a94060bb066.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_044005\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       12.94 GB / 14.61 GB (88.5%)\n",
      "Disk Space Avail:   21.67 GB / 223.03 GB (9.7%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_044005\"\n",
      "Train Data Rows:    300\n",
      "Train Data Columns: 7\n",
      "Label Column:       Yearly Amount Spent\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (712.3963268096637, 275.9184206503857, 496.65055, 72.48768)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13250.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Address']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 2\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Email']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Email']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 4 | ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']\n",
      "\t\t('object', [])       : 1 | ['Avatar']\n",
      "\t\t('object', ['text']) : 1 | ['Address']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['Avatar']\n",
      "\t\t('float', [])                       :  4 | ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']\n",
      "\t\t('int', ['binned', 'text_special']) : 11 | ['Address.char_count', 'Address.word_count', 'Address.capital_ratio', 'Address.lower_ratio', 'Address.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             :  2 | ['__nlp__.suite', '__nlp__._total_']\n",
      "\t0.4s = Fit runtime\n",
      "\t6 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.48s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 240, Val Rows: 60\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.52s of the 299.52s of remaining time.\n",
      "\t-70.3954\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 299.45s of the 299.45s of remaining time.\n",
      "\t-69.4317\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 299.4s of the 299.4s of remaining time.\n",
      "\t-23.4542\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 295.16s of the 295.16s of remaining time.\n",
      "\t-24.4447\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 292.7s of the 292.7s of remaining time.\n",
      "\t-25.8398\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 291.75s of the 291.75s of remaining time.\n",
      "\t-22.4597\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 289.47s of the 289.47s of remaining time.\n",
      "\t-24.9711\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 288.57s of the 288.56s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t-14.9812\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 285.34s of the 285.34s of remaining time.\n",
      "\t-26.0482\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 282.0s of the 282.0s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t-17.8843\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t4.68s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 277.25s of the 277.24s of remaining time.\n",
      "\t-24.7143\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.61s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.52s of the 266.51s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.765, 'NeuralNetTorch': 0.176, 'LightGBM': 0.059}\n",
      "\t-14.7067\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 33.73s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1763.0 rows/s (60 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_044005\")\n",
      "These features in provided data are not utilized by the predictor and will be ignored: ['Email']\n",
      "Computing feature importance via permutation shuffling for 6 features using 200 rows with 5 shuffle sets...\n",
      "\t5.02s\t= Expected runtime (1.0s per shuffle set)\n",
      "\t1.82s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_050612\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       12.86 GB / 14.61 GB (88.0%)\n",
      "Disk Space Avail:   21.63 GB / 223.03 GB (9.7%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_050612\"\n",
      "Train Data Rows:    300\n",
      "Train Data Columns: 7\n",
      "Label Column:       Yearly Amount Spent\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (712.3963268096637, 275.9184206503857, 496.65055, 72.48768)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    13172.18 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Address']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 2\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Email']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Email']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 4 | ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']\n",
      "\t\t('object', [])       : 1 | ['Avatar']\n",
      "\t\t('object', ['text']) : 1 | ['Address']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['Avatar']\n",
      "\t\t('float', [])                       :  4 | ['Avg. Session Length', 'Time on App', 'Time on Website', 'Length of Membership']\n",
      "\t\t('int', ['binned', 'text_special']) : 11 | ['Address.char_count', 'Address.word_count', 'Address.capital_ratio', 'Address.lower_ratio', 'Address.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             :  2 | ['__nlp__.suite', '__nlp__._total_']\n",
      "\t0.4s = Fit runtime\n",
      "\t6 features in original data used to generate 18 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.44s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 240, Val Rows: 60\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 299.56s of the 299.56s of remaining time.\n",
      "\t-70.3954\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 299.49s of the 299.49s of remaining time.\n",
      "\t-69.4317\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 299.43s of the 299.43s of remaining time.\n",
      "\t-23.4542\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 295.14s of the 295.14s of remaining time.\n",
      "\t-24.4447\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 292.6s of the 292.6s of remaining time.\n",
      "\t-25.8398\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 291.61s of the 291.61s of remaining time.\n",
      "\t-22.4597\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 289.12s of the 289.12s of remaining time.\n",
      "\t-24.9711\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 288.16s of the 288.16s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/fastai/learner.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(file, map_location=device, **torch_load_kwargs)\n",
      "\t-14.9812\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t3.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 284.69s of the 284.69s of remaining time.\n",
      "\t-26.0482\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 281.2s of the 281.2s of remaining time.\n",
      "/home/user/miniforge3/envs/automl/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py:411: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model = torch.load(net_filename)\n",
      "\t-17.8843\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 276.03s of the 276.03s of remaining time.\n",
      "\t-24.7143\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.56s of the 264.89s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.765, 'NeuralNetTorch': 0.176, 'LightGBM': 0.059}\n",
      "\t-14.7067\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 35.34s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2071.6 rows/s (60 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_050612\")\n",
      "These features in provided data are not utilized by the predictor and will be ignored: ['Email']\n",
      "Computing feature importance via permutation shuffling for 6 features using 200 rows with 5 shuffle sets...\n",
      "\t5.18s\t= Expected runtime (1.04s per shuffle set)\n",
      "\t1.89s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# automl 함수 정의\n",
    "def automl(data, target, time=300, metric=None):\n",
    "    if metric in (\"accuracy\", \"roc_auc\", \"recall\", \"precision\", \"f1\"):\n",
    "        train_data, test_data = train_test_split(data, stratify=data[target], test_size=0.4, random_state=10)\n",
    "    else:\n",
    "        train_data, test_data = train_test_split(data, test_size=0.4, random_state=10)\n",
    "        \n",
    "    model = TabularPredictor(label=target, eval_metric=metric)\n",
    "    model.fit(train_data, time_limit=time, presets='medium_quality')\n",
    "    pred = model.predict(test_data)\n",
    "\n",
    "    result = model.evaluate(test_data)\n",
    "    result_df = pd.DataFrame([result], index=[0])\n",
    "    # 여러 모델 성능 비교\n",
    "    leader_board = model.leaderboard(test_data)\n",
    "    # 중요 변수 출력\n",
    "    feature_importance = model.feature_importance(test_data)\n",
    "    best_model_name = model.model_best\n",
    "    # best모델 로딩\n",
    "    best_model = model._trainer.load_model(best_model_name)\n",
    "    best_model_params = best_model.params\n",
    "\n",
    "    return result_df, leader_board, feature_importance\n",
    "\n",
    "# 데이터 미리보기 (파일 업로드 후 head(3))\n",
    "def preview_data(file):\n",
    "    data = pd.read_csv(file.name)\n",
    "    return data.head(3)\n",
    "\n",
    "# Gradio 인터페이스 정의\n",
    "def gradio_automl(file, target, time, metric):\n",
    "    # CSV 파일을 pandas 데이터프레임으로 변환\n",
    "    data = pd.read_csv(file.name)\n",
    "\n",
    "    # automl 함수 호출\n",
    "    result_df, leader_board, feature_importance = automl(data, target, time, metric)\n",
    "    \n",
    "    return result_df, leader_board, feature_importance\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "with gr.Blocks() as demo:\n",
    "    file_input = gr.File(label=\"CSV 데이터 파일\")\n",
    "    data_preview = gr.Dataframe(label=\"데이터 미리보기 (head 3)\")\n",
    "    target_input = gr.Textbox(label=\"타겟 변수 이름\")\n",
    "    time_input = gr.Number(label=\"분석 시간 (초)\", value=300)\n",
    "    metric_input = gr.Dropdown(choices=[\"accuracy\", \"roc_auc\", \"recall\", \"precision\", \"f1\", None], label=\"성능 지표\")\n",
    "    \n",
    "    # 분석 결과 출력 (3개의 데이터프레임)\n",
    "    result_output = gr.Dataframe(label=\"Result Dataframe\")\n",
    "    leaderboard_output = gr.Dataframe(label=\"Leader Board\")\n",
    "    feature_importance_output = gr.Dataframe(label=\"Feature Importance\")\n",
    "\n",
    "    # 파일 업로드 시 데이터 미리보기 업데이트\n",
    "    file_input.change(fn=preview_data, inputs=file_input, outputs=data_preview)\n",
    "\n",
    "    # 분석 실행\n",
    "    submit_button = gr.Button(\"분석 실행\")\n",
    "    submit_button.click(fn=gradio_automl, inputs=[file_input, target_input, time_input, metric_input], outputs=[result_output, leaderboard_output, feature_importance_output])\n",
    "\n",
    "# Gradio 앱 실행 (공개 링크 제공)\n",
    "demo.launch(inline=False, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c7896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
