{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86164d81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install \"flaml[catboost]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf3d1e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3332c0fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def auto_predict(data, target_name, eval_metric='accuracy', time_limit=300):\n",
    "    target_column = target_name\n",
    "\n",
    "    time_limit = time_limit  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "    metric = 'accuracy'  # specify your evaluation metric here\n",
    "\n",
    "    model = TabularPredictor(label=target_column, eval_metric=metric)\n",
    "    model.fit(data, time_limit=time_limit, presets='good_quality_faster_inference_only_refit', num_stack_levels=0)\n",
    "    test_data = data.sample(frac=0.3, random_state=10)\n",
    "\n",
    "    pred = model.predict(test_data)\n",
    "\n",
    "    result = model.evaluate(test_data)\n",
    "    result_df = pd.DataFrame([result], index=[0])\n",
    "    leader_board = model.leaderboard(test_data)\n",
    "    feature_importance = model.feature_importance(test_data)\n",
    "    best_model_name = model.model_best\n",
    "    best_model = model._trainer.load_model(best_model_name)  # Load the best model\n",
    "    best_model_params = best_model.params\n",
    "\n",
    "\n",
    "    display(result_df)\n",
    "    print()\n",
    "    display(leader_board)\n",
    "    print()\n",
    "    display(feature_importance)\n",
    "    print(\"best_model\",best_model_name)\n",
    "    print(\"Best model hyperparameters:\")\n",
    "    print(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2fef2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/Taitanic_train.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "072c6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['PassengerId', 'Cabin', 'Ticket', 'Name', 'Fare'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54f43fc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_010115\"\n",
      "Preset alias specified: 'good_quality_faster_inference_only_refit' maps to 'good_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       11.49 GB / 14.61 GB (78.6%)\n",
      "Disk Space Avail:   23.57 GB / 223.03 GB (10.6%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality_faster_inference_only_refit']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Survived'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Survived'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mauto_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSurvived\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m, in \u001b[0;36mauto_predict\u001b[0;34m(data, target_name, eval_metric, time_limit)\u001b[0m\n\u001b[1;32m      5\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# specify your evaluation metric here\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m TabularPredictor(label\u001b[38;5;241m=\u001b[39mtarget_column, eval_metric\u001b[38;5;241m=\u001b[39mmetric)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgood_quality_faster_inference_only_refit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_stack_levels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m test_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     11\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39mother_args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1038\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     inferred_problem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     inferred_problem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learner\u001b[38;5;241m.\u001b[39minfer_problem_type(y\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1040\u001b[0m num_bag_folds, num_bag_sets, num_stack_levels, dynamic_stacking, use_bag_holdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_stack_args(\n\u001b[1;32m   1041\u001b[0m     num_bag_folds\u001b[38;5;241m=\u001b[39mnum_bag_folds,\n\u001b[1;32m   1042\u001b[0m     num_bag_sets\u001b[38;5;241m=\u001b[39mnum_bag_sets,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     use_bag_holdout\u001b[38;5;241m=\u001b[39muse_bag_holdout,\n\u001b[1;32m   1050\u001b[0m )\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_stack:\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Survived'"
     ]
    }
   ],
   "source": [
    "auto_predict(data, 'Survived', time_limit=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a7d18",
   "metadata": {},
   "source": [
    "# 연봉데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f4f697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age   workclass      education  education-num       marital-status  \\\n",
       "0   25     Private           11th              7        Never-married   \n",
       "1   38     Private        HS-grad              9   Married-civ-spouse   \n",
       "2   28   Local-gov     Assoc-acdm             12   Married-civ-spouse   \n",
       "3   44     Private   Some-college             10   Married-civ-spouse   \n",
       "4   18         NaN   Some-college             10        Never-married   \n",
       "\n",
       "           occupation relationship    race      sex  capital-gain  \\\n",
       "0   Machine-op-inspct    Own-child   Black     Male             0   \n",
       "1     Farming-fishing      Husband   White     Male             0   \n",
       "2     Protective-serv      Husband   White     Male             0   \n",
       "3   Machine-op-inspct      Husband   Black     Male          7688   \n",
       "4                 NaN    Own-child   White   Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week  native-country   class  \n",
       "0             0              40   United-States   <=50K  \n",
       "1             0              50   United-States   <=50K  \n",
       "2             0              40   United-States    >50K  \n",
       "3             0              40   United-States    >50K  \n",
       "4             0              30   United-States   <=50K  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/salary2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e55f4c33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_010146\"\n",
      "Preset alias specified: 'good_quality_faster_inference_only_refit' maps to 'good_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       11.49 GB / 14.61 GB (78.7%)\n",
      "Disk Space Avail:   23.57 GB / 223.03 GB (10.6%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality_faster_inference_only_refit']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_010146\"\n",
      "Train Data Rows:    48842\n",
      "Train Data Columns: 13\n",
      "Label Column:       class\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' <=50K', ' >50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11797.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 26.77 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 5 | ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.4s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.48s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 119.52s of the 119.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.14%)\n",
      "\t0.8698\t = Validation score   (accuracy)\n",
      "\t8.36s\t = Training   runtime\n",
      "\t2.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 106.06s of the 106.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
      "\t0.8749\t = Validation score   (accuracy)\n",
      "\t4.57s\t = Training   runtime\n",
      "\t1.18s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 97.82s of the 97.82s of remaining time.\n",
      "\t0.8654\t = Validation score   (accuracy)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 92.03s of the 92.03s of remaining time.\n",
      "\t0.8651\t = Validation score   (accuracy)\n",
      "\t3.34s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 86.87s of the 86.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
      "\t0.8741\t = Validation score   (accuracy)\n",
      "\t70.68s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 12.79s of the 12.78s of remaining time.\n",
      "\t0.8544\t = Validation score   (accuracy)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 8.14s of the 8.14s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 13.23s compared to 10s of available time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 5.05s of the 5.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.21%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "2024-10-17 10:03:51,042\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:03:51,044\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:03:51,047\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:03:51,049\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:03:51,051\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:03:51,053\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 10:03:51,055\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.52s of the -4.56s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.8749\t = Validation score   (accuracy)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 125.39s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5189.1 rows/s (6106 batch size)\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t1.5s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t0.89s\t = Training   runtime\n",
      "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t3.79s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t3.34s\t = Training   runtime\n",
      "\t1.17s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t12.58s\t = Training   runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.8s\t = Training   runtime\n",
      "\t1.2s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.61s\t = Training   runtime\n",
      "Updated best model to \"LightGBM_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"LightGBM_BAG_L1_FULL\" for predict() and predict_proba().\n",
      "Refit complete, total runtime = 19.5s ... Best model: \"LightGBM_BAG_L1_FULL\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_010146\")\n",
      "Computing feature importance via permutation shuffling for 13 features using 5000 rows with 5 shuffle sets...\n",
      "\t3.83s\t= Expected runtime (0.77s per shuffle set)\n",
      "\t2.08s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>mcc</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.881048</td>\n",
       "      <td>0.809407</td>\n",
       "      <td>0.659592</td>\n",
       "      <td>0.940433</td>\n",
       "      <td>0.730894</td>\n",
       "      <td>0.802101</td>\n",
       "      <td>0.671299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  balanced_accuracy       mcc   roc_auc        f1  precision  \\\n",
       "0  0.881048           0.809407  0.659592  0.940433  0.730894   0.802101   \n",
       "\n",
       "     recall  \n",
       "0  0.671299  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.893878</td>\n",
       "      <td>0.865444</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.724489</td>\n",
       "      <td>1.174646</td>\n",
       "      <td>3.794737</td>\n",
       "      <td>0.724489</td>\n",
       "      <td>1.174646</td>\n",
       "      <td>3.794737</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestGini_BAG_L1_FULL</td>\n",
       "      <td>0.893878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.828123</td>\n",
       "      <td>1.174646</td>\n",
       "      <td>3.794737</td>\n",
       "      <td>0.828123</td>\n",
       "      <td>1.174646</td>\n",
       "      <td>3.794737</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr_BAG_L1_FULL</td>\n",
       "      <td>0.889306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.626312</td>\n",
       "      <td>1.170672</td>\n",
       "      <td>3.341926</td>\n",
       "      <td>0.626312</td>\n",
       "      <td>1.170672</td>\n",
       "      <td>3.341926</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.889306</td>\n",
       "      <td>0.865075</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.666278</td>\n",
       "      <td>1.170672</td>\n",
       "      <td>3.341926</td>\n",
       "      <td>0.666278</td>\n",
       "      <td>1.170672</td>\n",
       "      <td>3.341926</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L1_FULL</td>\n",
       "      <td>0.881048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.071319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889536</td>\n",
       "      <td>0.071319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.889536</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2_FULL</td>\n",
       "      <td>0.881048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.077264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503325</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613789</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1_FULL</td>\n",
       "      <td>0.878250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.151568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503194</td>\n",
       "      <td>0.151568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503194</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_BAG_L1_FULL</td>\n",
       "      <td>0.877158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.577792</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.577792</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.869174</td>\n",
       "      <td>0.854408</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.616319</td>\n",
       "      <td>1.199986</td>\n",
       "      <td>2.795559</td>\n",
       "      <td>0.616319</td>\n",
       "      <td>1.199986</td>\n",
       "      <td>2.795559</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExtraTreesGini_BAG_L1_FULL</td>\n",
       "      <td>0.869174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.764339</td>\n",
       "      <td>1.199986</td>\n",
       "      <td>2.795559</td>\n",
       "      <td>0.764339</td>\n",
       "      <td>1.199986</td>\n",
       "      <td>2.795559</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874923</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.176163</td>\n",
       "      <td>4.571385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.176163</td>\n",
       "      <td>4.571385</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874923</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.180350</td>\n",
       "      <td>5.185174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.613789</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874125</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247316</td>\n",
       "      <td>70.682366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247316</td>\n",
       "      <td>70.682366</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.869825</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.224094</td>\n",
       "      <td>8.363166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.224094</td>\n",
       "      <td>8.363166</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  score_test  score_val eval_metric  \\\n",
       "0        RandomForestGini_BAG_L1    0.893878   0.865444    accuracy   \n",
       "1   RandomForestGini_BAG_L1_FULL    0.893878        NaN    accuracy   \n",
       "2   RandomForestEntr_BAG_L1_FULL    0.889306        NaN    accuracy   \n",
       "3        RandomForestEntr_BAG_L1    0.889306   0.865075    accuracy   \n",
       "4           LightGBM_BAG_L1_FULL    0.881048        NaN    accuracy   \n",
       "5       WeightedEnsemble_L2_FULL    0.881048        NaN    accuracy   \n",
       "6         LightGBMXT_BAG_L1_FULL    0.878250        NaN    accuracy   \n",
       "7           CatBoost_BAG_L1_FULL    0.877158        NaN    accuracy   \n",
       "8          ExtraTreesGini_BAG_L1    0.869174   0.854408    accuracy   \n",
       "9     ExtraTreesGini_BAG_L1_FULL    0.869174        NaN    accuracy   \n",
       "10               LightGBM_BAG_L1         NaN   0.874923    accuracy   \n",
       "11           WeightedEnsemble_L2         NaN   0.874923    accuracy   \n",
       "12               CatBoost_BAG_L1         NaN   0.874125    accuracy   \n",
       "13             LightGBMXT_BAG_L1         NaN   0.869825    accuracy   \n",
       "\n",
       "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0         0.724489       1.174646   3.794737                 0.724489   \n",
       "1         0.828123       1.174646   3.794737                 0.828123   \n",
       "2         0.626312       1.170672   3.341926                 0.626312   \n",
       "3         0.666278       1.170672   3.341926                 0.666278   \n",
       "4         0.071319            NaN   0.889536                 0.071319   \n",
       "5         0.077264            NaN   1.503325                 0.005945   \n",
       "6         0.151568            NaN   1.503194                 0.151568   \n",
       "7         0.032035            NaN  12.577792                 0.032035   \n",
       "8         0.616319       1.199986   2.795559                 0.616319   \n",
       "9         0.764339       1.199986   2.795559                 0.764339   \n",
       "10             NaN       1.176163   4.571385                      NaN   \n",
       "11             NaN       1.180350   5.185174                      NaN   \n",
       "12             NaN       0.247316  70.682366                      NaN   \n",
       "13             NaN       2.224094   8.363166                      NaN   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 1.174646           3.794737            1       True   \n",
       "1                 1.174646           3.794737            1       True   \n",
       "2                 1.170672           3.341926            1       True   \n",
       "3                 1.170672           3.341926            1       True   \n",
       "4                      NaN           0.889536            1       True   \n",
       "5                      NaN           0.613789            2       True   \n",
       "6                      NaN           1.503194            1       True   \n",
       "7                      NaN          12.577792            1       True   \n",
       "8                 1.199986           2.795559            1       True   \n",
       "9                 1.199986           2.795559            1       True   \n",
       "10                1.176163           4.571385            1      False   \n",
       "11                0.004187           0.613789            2      False   \n",
       "12                0.247316          70.682366            1      False   \n",
       "13                2.224094           8.363166            1      False   \n",
       "\n",
       "    fit_order  \n",
       "0           3  \n",
       "1          10  \n",
       "2          11  \n",
       "3           4  \n",
       "4           9  \n",
       "5          14  \n",
       "6           8  \n",
       "7          12  \n",
       "8           6  \n",
       "9          13  \n",
       "10          2  \n",
       "11          7  \n",
       "12          5  \n",
       "13          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>capital-gain</th>\n",
       "      <td>0.05860</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>2.961204e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.063385</td>\n",
       "      <td>0.053815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education-num</th>\n",
       "      <td>0.02292</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>7.632572e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.027146</td>\n",
       "      <td>0.018694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.02228</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>2.940198e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.028050</td>\n",
       "      <td>0.016510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>3.450193e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.025393</td>\n",
       "      <td>0.014607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0.01624</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>1.142368e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.010305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital-loss</th>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>8.925098e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.013136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital-status</th>\n",
       "      <td>0.01156</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>9.715804e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>0.004197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hours-per-week</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>2.862003e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.018539</td>\n",
       "      <td>0.001461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0.00420</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>1.212718e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0.00212</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>6.650888e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0.00104</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>2.431512e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>-0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>1.209908e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>-0.001131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.00044</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>1.824216e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>-0.001544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                importance    stddev       p_value  n  p99_high   p99_low\n",
       "capital-gain       0.05860  0.002324  2.961204e-07  5  0.063385  0.053815\n",
       "education-num      0.02292  0.002052  7.632572e-06  5  0.027146  0.018694\n",
       "age                0.02228  0.002802  2.940198e-05  5  0.028050  0.016510\n",
       "occupation         0.02000  0.002619  3.450193e-05  5  0.025393  0.014607\n",
       "relationship       0.01624  0.002882  1.142368e-04  5  0.022175  0.010305\n",
       "capital-loss       0.01472  0.000769  8.925098e-07  5  0.016304  0.013136\n",
       "marital-status     0.01156  0.003576  9.715804e-04  5  0.018923  0.004197\n",
       "hours-per-week     0.01000  0.004147  2.862003e-03  5  0.018539  0.001461\n",
       "workclass          0.00420  0.001378  1.212718e-03  5  0.007038  0.001362\n",
       "native-country     0.00212  0.000593  6.650888e-04  5  0.003342  0.000898\n",
       "race               0.00104  0.000829  2.431512e-02  5  0.002748 -0.000668\n",
       "education          0.00048  0.000782  1.209908e-01  5  0.002091 -0.001131\n",
       "sex                0.00044  0.000963  1.824216e-01  5  0.002424 -0.001544"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model LightGBM_BAG_L1_FULL\n",
      "Best model hyperparameters:\n",
      "{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n"
     ]
    }
   ],
   "source": [
    "auto_predict(data, 'class', time_limit=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b829e0ec",
   "metadata": {},
   "source": [
    "# 회귀분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d555640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>범죄율</th>\n",
       "      <th>25,000평방피트초과</th>\n",
       "      <th>비소매상업지역비율</th>\n",
       "      <th>찰스강경계</th>\n",
       "      <th>농축 일산화질소</th>\n",
       "      <th>가구당평균방수</th>\n",
       "      <th>1940년이전건축비율</th>\n",
       "      <th>직업센터접근성</th>\n",
       "      <th>도로접근성</th>\n",
       "      <th>재산세율</th>\n",
       "      <th>학생/교사비율</th>\n",
       "      <th>흑인비율</th>\n",
       "      <th>하위계층비율</th>\n",
       "      <th>주택가격</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         범죄율  25,000평방피트초과  비소매상업지역비율  찰스강경계  농축 일산화질소  가구당평균방수  1940년이전건축비율  \\\n",
       "0    0.00632          18.0       2.31      0     0.538    6.575         65.2   \n",
       "1    0.02731           0.0       7.07      0     0.469    6.421         78.9   \n",
       "2    0.02729           0.0       7.07      0     0.469    7.185         61.1   \n",
       "3    0.03237           0.0       2.18      0     0.458    6.998         45.8   \n",
       "4    0.06905           0.0       2.18      0     0.458    7.147         54.2   \n",
       "..       ...           ...        ...    ...       ...      ...          ...   \n",
       "501  0.06263           0.0      11.93      0     0.573    6.593         69.1   \n",
       "502  0.04527           0.0      11.93      0     0.573    6.120         76.7   \n",
       "503  0.06076           0.0      11.93      0     0.573    6.976         91.0   \n",
       "504  0.10959           0.0      11.93      0     0.573    6.794         89.3   \n",
       "505  0.04741           0.0      11.93      0     0.573    6.030         80.8   \n",
       "\n",
       "     직업센터접근성  도로접근성   재산세율  학생/교사비율    흑인비율  하위계층비율  주택가격  \n",
       "0     4.0900      1  296.0     15.3  396.90    4.98  24.0  \n",
       "1     4.9671      2  242.0     17.8  396.90    9.14  21.6  \n",
       "2     4.9671      2  242.0     17.8  392.83    4.03  34.7  \n",
       "3     6.0622      3  222.0     18.7  394.63    2.94  33.4  \n",
       "4     6.0622      3  222.0     18.7  396.90    5.33  36.2  \n",
       "..       ...    ...    ...      ...     ...     ...   ...  \n",
       "501   2.4786      1  273.0     21.0  391.99    9.67  22.4  \n",
       "502   2.2875      1  273.0     21.0  396.90    9.08  20.6  \n",
       "503   2.1675      1  273.0     21.0  396.90    5.64  23.9  \n",
       "504   2.3889      1  273.0     21.0  393.45    6.48  22.0  \n",
       "505   2.5050      1  273.0     21.0  396.90    7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/01%EB%B3%B4%EC%8A%A4%ED%84%B4%EC%A7%91%EA%B0%92%EB%8D%B0%EC%9D%B4%ED%84%B0.csv\", encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3390cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 10:13:33,388\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:13:33,390\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:13:33,392\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:13:33,395\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:13:33,398\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:13:33,400\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:13:33,402\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    }
   ],
   "source": [
    "# root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8e4aeb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_011357\"\n",
      "Preset alias specified: 'good_quality_faster_inference_only_refit' maps to 'good_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       11.33 GB / 14.61 GB (77.6%)\n",
      "Disk Space Avail:   23.16 GB / 223.03 GB (10.4%)\n",
      "===================================================\n",
      "Presets specified: ['good_quality_faster_inference_only_refit']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
      "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_011357\"\n",
      "Train Data Rows:    506\n",
      "Train Data Columns: 13\n",
      "Label Column:       주택가격\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (50.0, 5.0, 22.53281, 9.1971)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11606.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 11 | ['범죄율', '25,000평방피트초과', '비소매상업지역비율', '농축 일산화질소', '가구당평균방수', ...]\n",
      "\t\t('int', [])   :  2 | ['찰스강경계', '도로접근성']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 11 | ['범죄율', '25,000평방피트초과', '비소매상업지역비율', '농축 일산화질소', '가구당평균방수', ...]\n",
      "\t\t('int', [])       :  1 | ['도로접근성']\n",
      "\t\t('int', ['bool']) :  1 | ['찰스강경계']\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 599.87s of the 599.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=59766, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 128, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/engine.py\", line 283, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4159, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4160, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4868, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 45, in function_template\n",
      "    return metric.name, metric(y_true, y_hat), is_higher_better\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=59766, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 128, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/engine.py\", line 283, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4159, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4160, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4868, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 45, in function_template\n",
      "    return metric.name, metric(y_true, y_hat), is_higher_better\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 593.07s of the 593.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "2024-10-17 10:14:10,409\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:10,412\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:10,413\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:10,416\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:10,418\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:10,421\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:10,423\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=60108, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 128, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/engine.py\", line 283, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4159, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4160, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4868, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 45, in function_template\n",
      "    return metric.name, metric(y_true, y_hat), is_higher_better\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=60108, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 128, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/engine.py\", line 283, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4159, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4160, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4868, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 45, in function_template\n",
      "    return metric.name, metric(y_true, y_hat), is_higher_better\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 586.92s of the 586.91s of remaining time.\n",
      "\tWarning: Exception caused RandomForestMSE_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tcontinuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n",
      "    self._fit_single(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 542, in _fit_single\n",
      "    model_base.val_score = model_base.score_with_y_pred_proba(y=y, y_pred_proba=self._oof_pred_proba)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "2024-10-17 10:14:12,047\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:12,049\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:12,051\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:12,053\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:12,056\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:12,058\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:12,060\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 585.66s of the 585.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=60433, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 405, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 422, in _ray_predict_oof\n",
      "    fold_model.val_score = fold_model.score_with_y_pred_proba(y=y_val_fold, y_pred_proba=y_pred_proba)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=60433, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 405, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 422, in _ray_predict_oof\n",
      "    fold_model.val_score = fold_model.score_with_y_pred_proba(y=y_val_fold, y_pred_proba=y_pred_proba)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 576.99s of the 576.99s of remaining time.\n",
      "\tWarning: Exception caused ExtraTreesMSE_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tcontinuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 263, in _fit\n",
      "    self._fit_single(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 542, in _fit_single\n",
      "    model_base.val_score = model_base.score_with_y_pred_proba(y=y, y_pred_proba=self._oof_pred_proba)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "2024-10-17 10:14:21,847\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:21,849\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:21,851\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:21,853\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:21,856\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:21,859\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:21,860\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 575.86s of the 575.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=60861, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 405, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 422, in _ray_predict_oof\n",
      "    fold_model.val_score = fold_model.score_with_y_pred_proba(y=y_val_fold, y_pred_proba=y_pred_proba)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=60861, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 405, in _ray_fit\n",
      "    fold_model, pred_proba = _ray_predict_oof(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 422, in _ray_predict_oof\n",
      "    fold_model.val_score = fold_model.score_with_y_pred_proba(y=y_val_fold, y_pred_proba=y_pred_proba)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1063, in score_with_y_pred_proba\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 565.42s of the 565.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=61280, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/training.py\", line 182, in train\n",
      "    if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/callback.py\", line 238, in after_iteration\n",
      "    score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/core.py\", line 2139, in eval_set\n",
      "    feval_ret = feval(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/sklearn.py\", line 126, in inner\n",
      "    return func.__name__, func(y_true, y_score)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 54, in custom_metric\n",
      "    return sign * metric(y_true, y_hat)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=61280, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 153, in _fit\n",
      "    self.model.fit(X=X, y=y, eval_set=eval_set, verbose=False, sample_weight=sample_weight)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1090, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/training.py\", line 182, in train\n",
      "    if cb_container.after_iteration(bst, i, dtrain, evals):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/callback.py\", line 238, in after_iteration\n",
      "    score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/core.py\", line 2139, in eval_set\n",
      "    feval_ret = feval(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/xgboost/sklearn.py\", line 126, in inner\n",
      "    return func.__name__, func(y_true, y_score)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/xgboost/xgboost_utils.py\", line 54, in custom_metric\n",
      "    return sign * metric(y_true, y_hat)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 10:14:36,634\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:36,635\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:36,637\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:36,638\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:36,642\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:36,645\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:36,646\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 561.07s of the 561.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "2024-10-17 10:14:41,442\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:42,442\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:42,444\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:42,446\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:42,448\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:42,450\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:42,453\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=61583, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 208, in _fit\n",
      "    self._train_net(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 350, in _train_net\n",
      "    val_metric = self.score(X=val_dataset, y=y_val, metric=self.stopping_metric, _reset_threads=False)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1054, in score\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=61583, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 208, in _fit\n",
      "    self._train_net(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 350, in _train_net\n",
      "    val_metric = self.score(X=val_dataset, y=y_val, metric=self.stopping_metric, _reset_threads=False)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1054, in score\n",
      "    return compute_weighted_metric(y, y_pred, metric, sample_weight, quantile_levels=self.quantile_levels)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/utils/utils.py\", line 673, in compute_weighted_metric\n",
      "    return metric(y, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 549.96s of the 549.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.09%)\n",
      "2024-10-17 10:14:53,464\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:53,466\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:53,467\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:53,470\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:53,472\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:53,475\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:53,476\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=62007, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 128, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/engine.py\", line 283, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4159, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4160, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4868, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 45, in function_template\n",
      "    return metric.name, metric(y_true, y_hat), is_higher_better\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::_ray_fit()\u001b[39m (pid=62007, ip=172.17.7.15)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 218, in _fit\n",
      "    self.model = train_lgb_model(early_stopping_callback_kwargs=early_stopping_callback_kwargs, **train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 128, in train_lgb_model\n",
      "    return lgb.train(**train_params)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/engine.py\", line 283, in train\n",
      "    evaluation_result_list.extend(booster.eval_valid(feval))\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4159, in eval_valid\n",
      "    return [item for i in range(1, self.__num_dataset)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4160, in <listcomp>\n",
      "    for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/lightgbm/basic.py\", line 4868, in __inner_eval\n",
      "    feval_ret = eval_function(self.__inner_predict(data_idx), cur_data)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/models/lgb/lgb_utils.py\", line 45, in function_template\n",
      "    return metric.name, metric(y_true, y_hat), is_higher_better\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 96, in __call__\n",
      "    return self._score(y_true=y_true, y_pred=y_pred, **k)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/metrics/__init__.py\", line 134, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 213, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/home/user/miniforge3/envs/ag/lib/python3.10/site-packages/sklearn/metrics/_classification.py\", line 105, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No base models to train on, skipping auxiliary stack level 2...\n",
      "Warning: AutoGluon did not successfully train any models\n",
      "AutoGluon training complete, total runtime = 56.23s ... Best model: None\n",
      "Warning: No models found, skipping post_fit logic...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_011357\")\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Trainer has no fit models that can infer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mauto_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m주택가격\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroot_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m, in \u001b[0;36mauto_predict\u001b[0;34m(data, target_name, eval_metric, time_limit)\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(data, time_limit\u001b[38;5;241m=\u001b[39mtime_limit, presets\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgood_quality_faster_inference_only_refit\u001b[39m\u001b[38;5;124m'\u001b[39m, num_stack_levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      9\u001b[0m test_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_data)\n\u001b[1;32m     14\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([result], index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:2117\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2116\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_threshold\n\u001b[0;32m-> 2117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:208\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    207\u001b[0m X_index \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(X\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;28;01mif\u001b[39;00m as_pandas \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_multiclass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m problem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cleaner\u001b[38;5;241m.\u001b[39mproblem_type_transform \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type\n\u001b[1;32m    212\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39mproblem_type, decision_threshold\u001b[38;5;241m=\u001b[39mdecision_threshold)\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/tabular/learner/abstract_learner.py:189\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform_features:\n\u001b[1;32m    188\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features(X)\n\u001b[0;32m--> 189\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m     y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, as_pandas\u001b[38;5;241m=\u001b[39mas_pandas, index\u001b[38;5;241m=\u001b[39mX_index, as_multiclass\u001b[38;5;241m=\u001b[39mas_multiclass, inverse_transform\u001b[38;5;241m=\u001b[39minverse_transform\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_proba\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:835\u001b[0m, in \u001b[0;36mAbstractTrainer.predict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 835\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m     cascade \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba_model(X, model, cascade\u001b[38;5;241m=\u001b[39mcascade)\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:843\u001b[0m, in \u001b[0;36mAbstractTrainer._get_best\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/ag/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py:1517\u001b[0m, in \u001b[0;36mAbstractTrainer.get_model_best\u001b[0;34m(self, can_infer, allow_full, infer_limit, infer_limit_as_child)\u001b[0m\n\u001b[1;32m   1515\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names(can_infer\u001b[38;5;241m=\u001b[39mcan_infer)\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[0;32m-> 1517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can infer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1518\u001b[0m models_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_models_attribute_dict(models\u001b[38;5;241m=\u001b[39mmodels, attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefit_full_parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_full:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Trainer has no fit models that can infer."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 10:14:59,469\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:59,470\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:59,472\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:59,474\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:59,476\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:59,479\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-10-17 10:14:59,485\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
     ]
    }
   ],
   "source": [
    "auto_predict(data, '주택가격', eval_metric='root_mean_squared_error', time_limit=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb7dfa7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241017_011612\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Fri Mar 29 23:14:13 UTC 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       11.33 GB / 14.61 GB (77.5%)\n",
      "Disk Space Avail:   23.16 GB / 223.03 GB (10.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 75s of the 300s of remaining time (25%).\n",
      "\t\tContext path: \"AutogluonModels/ag-20241017_011612/ds_sub_fit/sub_fit_ho\"\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout  score_val              eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3      -2.181523  -2.906414  root_mean_squared_error        2.439022       0.714003  47.961493                 0.007925                0.000515           0.016221            3       True         12\n",
      "1          LightGBM_BAG_L2      -2.184631  -3.000239  root_mean_squared_error        2.278381       0.609518  42.831974                 0.080300                0.029488           2.563562            2       True         11\n",
      "2          CatBoost_BAG_L1      -2.247965  -3.029759  root_mean_squared_error        0.363066       0.015054  24.609805                 0.363066                0.015054          24.609805            1       True          6\n",
      "3     ExtraTreesMSE_BAG_L1      -2.249066  -3.288110  root_mean_squared_error        0.195492       0.117928   0.939300                 0.195492                0.117928           0.939300            1       True          7\n",
      "4      WeightedEnsemble_L2      -2.292443  -3.001123  root_mean_squared_error        1.461427       0.286731  32.626398                 0.007740                0.000651           0.014242            2       True          9\n",
      "5        LightGBMXT_BAG_L2      -2.330308  -3.101012  root_mean_squared_error        2.350797       0.684000  45.381710                 0.152715                0.103970           5.113299            2       True         10\n",
      "6        LightGBMXT_BAG_L1      -2.434039  -3.259977  root_mean_squared_error        0.699276       0.132370   3.377832                 0.699276                0.132370           3.377832            1       True          3\n",
      "7          LightGBM_BAG_L1      -2.484647  -3.310976  root_mean_squared_error        0.134205       0.051105   3.755618                 0.134205                0.051105           3.755618            1       True          4\n",
      "8   RandomForestMSE_BAG_L1      -2.825798  -3.359171  root_mean_squared_error        0.257140       0.087552   0.868901                 0.257140                0.087552           0.868901            1       True          5\n",
      "9   NeuralNetFastAI_BAG_L1      -5.024907  -5.975227  root_mean_squared_error        0.523472       0.170102   6.523092                 0.523472                0.170102           6.523092            1       True          8\n",
      "10   KNeighborsDist_BAG_L1      -5.113589  -6.151995  root_mean_squared_error        0.012457       0.002990   0.005525                 0.012457                0.002990           0.005525            1       True          2\n",
      "11   KNeighborsUnif_BAG_L1      -5.375645  -6.372194  root_mean_squared_error        0.012974       0.002929   0.188338                 0.012974                0.002929           0.188338            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t87s\t = DyStack   runtime |\t213s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 213s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241017_011612\"\n",
      "Train Data Rows:    506\n",
      "Train Data Columns: 13\n",
      "Label Column:       주택가격\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    11104.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 11 | ['범죄율', '25,000평방피트초과', '비소매상업지역비율', '농축 일산화질소', '가구당평균방수', ...]\n",
      "\t\t('int', [])   :  2 | ['찰스강경계', '도로접근성']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 11 | ['범죄율', '25,000평방피트초과', '비소매상업지역비율', '농축 일산화질소', '가구당평균방수', ...]\n",
      "\t\t('int', [])       :  1 | ['도로접근성']\n",
      "\t\t('int', ['bool']) :  1 | ['찰스강경계']\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 142.09s of the 213.18s of remaining time.\n",
      "\t-6.118\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 141.92s of the 213.0s of remaining time.\n",
      "\t-5.8997\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 141.74s of the 212.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-3.002\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.23s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 131.89s of the 202.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-3.1024\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.45s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 118.94s of the 190.02s of remaining time.\n",
      "\t-3.2218\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 117.71s of the 188.8s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-2.8277\t = Validation score   (-root_mean_squared_error)\n",
      "\t94.49s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 19.27s of the 90.35s of remaining time.\n",
      "\t-3.1109\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 17.94s of the 89.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.00%)\n",
      "\t-3.7906\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.41s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4.09s of the 75.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t-3.0356\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.8s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 213.19s of the 65.87s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.44, 'XGBoost_BAG_L1': 0.32, 'LightGBMXT_BAG_L1': 0.2, 'KNeighborsDist_BAG_L1': 0.04}\n",
      "\t-2.7392\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 65.76s of the 65.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-2.8537\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.67s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 59.18s of the 59.1s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-2.9887\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.3s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 51.44s of the 51.36s of remaining time.\n",
      "\t-2.9435\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 50.27s of the 50.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
      "\t-2.7837\t = Validation score   (-root_mean_squared_error)\n",
      "\t40.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 6.04s of the 5.95s of remaining time.\n",
      "\t-2.7933\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 5.07s of the 4.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t-3.1252\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.71s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 213.19s of the -9.15s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.28, 'CatBoost_BAG_L1': 0.24, 'XGBoost_BAG_L1': 0.2, 'ExtraTreesMSE_BAG_L2': 0.16, 'LightGBMXT_BAG_L1': 0.08, 'LightGBMXT_BAG_L2': 0.04}\n",
      "\t-2.7118\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 222.68s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 69.7 rows/s (64 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241017_011612\")\n",
      "Computing feature importance via permutation shuffling for 13 features using 152 rows with 5 shuffle sets...\n",
      "\t155.1s\t= Expected runtime (31.02s per shuffle set)\n"
     ]
    }
   ],
   "source": [
    "target_column = '주택가격'\n",
    "\n",
    "time_limit = 300  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'root_mean_squared_error'  # specify your evaluation metric here\n",
    "\n",
    "model = TabularPredictor(label=target_column, eval_metric=metric)\n",
    "model.fit(data, time_limit=time_limit, presets='best_quality' )\n",
    "test_data = data.sample(frac=0.3, random_state=10)\n",
    "\n",
    "pred = model.predict(test_data)\n",
    "\n",
    "result = model.evaluate(test_data)\n",
    "result_df = pd.DataFrame(result, index=result.keys())\n",
    "leader_board = model.leaderboard(test_data)\n",
    "feature_importance = model.feature_importance(test_data)\n",
    "best_model_name = model.model_best\n",
    "best_model = model._trainer.load_model(best_model_name)  # Load the best model\n",
    "best_model_params = best_model.params\n",
    "\n",
    "\n",
    "display(result_df)\n",
    "print()\n",
    "display(leader_board)\n",
    "print()\n",
    "display(feature_importance)\n",
    "print(\"best_model\",best_model_name)\n",
    "print(\"Best model hyperparameters:\")\n",
    "print(best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aec446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25948bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/ratings_train.txt\", sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e7b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0de7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce008d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../06machine_learning/data/house_train.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055fa2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auto_predict(data, 'SalePrice', eval_metric='root_mean_squared_error', time_limit=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1fe193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
